{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to the Website","text":""},{"location":"#come-back-for-more","title":"Come back for more","text":"<p>Welcome</p> IntroAim <pre><code>* This site is for demonstration purposes.\n</code></pre> <pre><code>1. Understand mkdocs.\n</code></pre>"},{"location":"banner/","title":"SSHD Banner Text","text":""},{"location":"banner/#generation-script","title":"Generation Script","text":"<p>Source:  To run: <code>bash box_gen.sh \"Text Here\" or \"Filename\"</code></p> <p>Boxed Text Generation</p> box_gen.shfile1.txtbanner.txt <pre><code>cat &gt; ~/box_gen.sh &lt;&lt;EOW\n#!/bin/bash\n\n# Check if an argument is provided\nif [ -z \"$1\" ]; then\n    echo \"Usage: $0 \\\"Your text here\\\" or $0 file2\"\n    exit 1\nfi\n\n# Check if the input is a file or text\nif [ -f \"$1\" ]; then\n    # Read the contents of the file\n    text=$(&lt;\"$1\")\nelse\n    # Treat the argument as text\n    text=\"$1\"\nfi\n\nOUT_FILE=\"banner.txt\"\n\n# Define fixed box width for content\ncontent_width=40\nbox_width=$((content_width + 4)) # Add space for padding and borders\n\n# Generate the top and bottom borders\nborder=$(printf '#%.0s' $(seq 1 $box_width))\n\n# Function to wrap text within the content width\nwrap_text() {\n    echo \"$1\" | fold -sw $content_width\n}\n\n# Write the content to the file\n{\n    echo \"$border\"\n    printf \"#%-*s#\\n\" $((box_width - 2)) \"\"\n    printf \"#%-*s#\\n\" $((box_width - 2)) \"         Update\"\n    printf \"#%-*s#\\n\" $((box_width - 2)) \"         ----------\"\n    printf \"#%-*s#\\n\" $((box_width - 2)) \"\"\n\n    # Add the wrapped text line by line\n    while IFS= read -r line; do\n        printf \"# %-*s #\\n\" $content_width \"$line\"\n    done &lt; &lt;(wrap_text \"$text\")\n\n    printf \"#%-*s#\\n\" $((box_width - 2)) \"\"\n    echo \"$border\"\n} &gt; $OUT_FILE\n\necho \"Text written to $OUT_FILE successfully.\"\nEOW\n</code></pre> <pre><code>cat &gt; ~/file1.txt &lt;&lt;EOW\nLorem Ipsum is simply dummy text of the printing and typesetting industry. Lorem Ipsum has been the industry's standard dummy text ever since the 1500s, when an unknown printer took a galley of type and scrambled it to make a type specimen book. It has survived not only five centuries, but also the leap into electronic typesetting, remaining essentially unchanged. It was popularised in the 1960s with the release of Letraset sheets containing Lorem Ipsum passages, and more recently with desktop publishing software like Aldus PageMaker including versions of Lorem Ipsum.\nEOW\n</code></pre> <pre><code>############################################\n#                                          #\n#         Update                           #\n#         ----------                       #\n#                                          #\n# Lorem Ipsum is simply dummy text of the  #\n# printing and typesetting industry.       #\n# Lorem Ipsum has been the industry's      #\n# standard dummy text ever since the       #\n# 1500s, when an unknown printer took a    #\n# galley of type and scrambled it to make  #\n# a type specimen book. It has survived    #\n# not only five centuries, but also the    #\n# leap into electronic typesetting,        #\n# remaining essentially unchanged. It was  #\n# popularised in the 1960s with the        #\n# release of Letraset sheets containing    #\n# Lorem Ipsum passages, and more recently  #\n# with desktop publishing software like    #\n# Aldus PageMaker including versions of    #\n# Lorem Ipsum.                             #\n#                                          #\n############################################\n</code></pre>"},{"location":"cgroup/","title":"Welcome to the CGroup Implementation","text":""},{"location":"cgroup/#hpc-cgroup-logon","title":"HPC CGroup Logon","text":"<p>Source:  Follow this implementation of cgroups.</p> <p>Control Group Implementation</p> user.sliceuser-.slice <pre><code>cat &gt; /etc/systemd/system/user.slice &lt;&lt;EOW\n# /etc/systemd/system/user.slice\n# Source: https://hpc-syspros-basics.github.io/Advanced_Topics/Login_Node_Resource_Management/cgroups.html\n# \n# CPUQuota = 100% # 4 cores * 100 * 0.25 \n#          = 100% \n#     - to limit 1 core for each user \n#       in a system with 4 cores total\n# Set MemoryHigh and MemoryMax as per \n# requirement \n# e.g., 1% = 17.7 MB verified inside a\n# TEST env\n# MemorySwapMax = 0% means no swap usage for users\n#  SPDX-License-Identifier: LGPL-2.1+\n#\n#  This file is part of systemd.\n#\n#  systemd is free software; you can redistribute it and/or modify it\n#  under the terms of the GNU Lesser General Public License as published by\n#  the Free Software Foundation; either version 2.1 of the License, or\n#  (at your option) any later version.\n\n[Unit]\nDescription=User and Session Slice\nDocumentation=man:systemd.special(7)\nBefore=slices.target\n\n[Slice]\nCPUQuota=100%\nMemoryHigh=1%\nMemoryMax=1%\nMemorySwapMax=0%\nEOW\n</code></pre> <pre><code>cat &gt; /etc/systemd/system/user-.slice.d/10-defaults.conf &lt;&lt;EOW\n# /etc/systemd/system/user-.slice.d/10-defaults.conf\n#  SPDX-License-Identifier: LGPL-2.1+\n#\n#  This file is part of systemd.\n#\n#  systemd is free software; you can redistribute it and/or modify it\n#  under the terms of the GNU Lesser General Public License as published by\n#  the Free Software Foundation; either version 2.1 of the License, or\n#  (at your option) any later version.\n\n[Unit]\nDescription=User Slice of UID %j\nAfter=systemd-user-sessions.service\n\n[Slice]\nTasksMax=80%\nCPUQuota=320%\nMemoryHigh=10M\nMemoryMax=11M\nMemorySwapMax=0G\nSwappiness=0M\nEOW\n</code></pre> <p>Reload systemctl daemon</p> <pre><code>systemctl daemon-reload\n</code></pre> <p>Now, the users will be placed in new cgroups with new limits.</p> <p>To verify, </p> <pre><code>systemctl status user.slice\n\nsystemctl status user-0.status\n</code></pre>"},{"location":"mpi/","title":"Welcome to the MPI","text":""},{"location":"mpi/#debug-errors","title":"Debug Errors","text":"<p>srun</p> submit.slErrorDebughelloworld_mpi.c <pre><code>#!/bin/bash -x\n#SBATCH --job-name=helloworld_mpi\n##SBATCH --mail-user=\"&lt;your-email-address&gt;\"\n##SBATCH --mail-type=\"ALL\"\n#SBATCH --time=00:00:10\n#SBATCH --partition=parallel\n#SBATCH --output=%x_%j.out\n#SBATCH --nodes=2\n#SBATCH --ntasks=10\n#SBATCH --mem-per-cpu=1G\n#SBATCH --constraint=\"IB\"\n\n# making sure we start with a clean module environment\nmodule purge\n\necho \"## Loading module\"\nml purge; ml gnu9/9.4.0 openmpi4/4.1.1 ohpc config; ml list\n# Compile program\nmpicc helloworld_mpi.c -o helloworld_mpi\n\nTEST_DIR=$(pwd)\necho \"## Current dircectory $TEST_DIR\"\n\necho \"## Running test\"\n#Failure: srun errors while mpirun does not\n#srun ./helloworld_mpi\n#Success: testing with mpi version specific, works\nsrun --mpi=pmi2 ./helloworld_mpi\n#Success: alternative command, but not needed because srun takes care of it\n#mpirun -np $SLURM_NTASKS ./helloworld_mpi\n\necho \"## Test finished. Goodbye\"\n</code></pre> <pre><code>--------------------------------------------------------------------------\nThe application appears to have been direct launched using \"srun\",\nbut OMPI was not built with SLURM's PMI support and therefore cannot\nexecute. There are several options for building PMI support under\nSLURM, depending upon the SLURM version you are using:\n\nversion 16.05 or later: you can use SLURM's PMIx support. This\nrequires that you configure and build SLURM --with-pmix.\n\nVersions earlier than 16.05: you must use either SLURM's PMI-1 or\nPMI-2 support. SLURM builds PMI-1 by default, or you can manually\ninstall PMI-2. You must then build Open MPI using --with-pmi pointing\nto the SLURM PMI library location.\n\nPlease configure as appropriate and try again.\n--------------------------------------------------------------------------\n</code></pre> <pre><code># Debug mpi\nOMPI_MCA_pmix_base_verbose=10 srun ./helloworld_mpi\n\n# Check mpi info\nompi_info\n\n# Debug slurm\nSLURM_DEBUG=2 srun --export=\"NCCL_DEBUG=INFO,NCCL_IB_DISABLE=1,PMIX_MCA_gds=hash\" \n    --mpi=pmix_v4 -N 1 --ntasks=1 -w amd01n01 ./helloworld_mpi\n\n# Verify mpi or pmix implementation\nsrun --mpi=list\n\n# Run from login node\nSLURM_DEBUG=2 srun --export=\"NCCL_DEBUG=INFO,NCCL_IB_DISABLE=1,PMIX_MCA_gds=hash\" \n    --mpi=pmix -N 1 --ntasks=1 -w amd01n01 ./helloworld_mpi\n</code></pre> <pre><code>#include &lt;stdio.h&gt;\n#include &lt;mpi.h&gt;\n\nint main (int argc, char *argv[])\n{\nint i, rank, size, processor_name_len;\nchar name [MPI_MAX_PROCESSOR_NAME];\n\nMPI_Init (&amp;argc, &amp;argv);\n\nMPI_Comm_size (MPI_COMM_WORLD, &amp;size);\nMPI_Comm_rank (MPI_COMM_WORLD, &amp;rank);\nMPI_Get_processor_name (name, &amp;processor_name_len);\n\nprintf (\"Hello World from rank %03d out of %03d running on %s!\\n\", rank, size, name);\n\nif (rank == 0 )\n    printf (\"MPI World size = %d processes\\n\", size);\n\nMPI_Finalize ();\nreturn 0;\n}\n</code></pre>"},{"location":"proxy/","title":"Welcome to the ProxyCommand Setup","text":""},{"location":"proxy/#slurm-ssh-proxy","title":"Slurm SSH Proxy","text":"<p>Source:  Follow this implementation of slurm-ssh-node-proxycommand.</p> <p>slurm ssh node proxycommand</p> slurm-ssh-node-proxycommand~/.ssh/configssh-copy-id <pre><code>cat &gt; /nfs/home/$USER/slurm-ssh-node-proxycommand &lt;&lt;EOW\n#!/bin/bash\n\nJOBID=$(sbatch --output=/dev/null --error=/dev/null -J shell-proxycommand --wrap=\"sleep 32000000\" --parsable \"$@\")\nret=$?\nif [ $ret -ne 0 ];then\n    exit $ret\nfi\n\ntrap \"{ scancel --quiet $JOBID ; exit ; }\" SIGINT SIGTERM EXIT\n\nwhile true ; do\n    sleep 1\n    state=$(squeue -j $JOBID -O State --noheader)\n    #echo \"'$state'\" &gt; /dev/stderr\n    case $state in\n        RUNNING*)\n            #echo \"running\" &gt; /dev/stderr\n            break\n            ;;\n        PENDING*|CONFIGURING*)\n            #echo \"waiting: $state\" &gt; /dev/stderr\n            ;;\n        *)\n            echo \"Failed: unknown job state \\\"$state\\\"\" &gt; /dev/stderr\n            exit 1\n            ;;\n    esac\ndone\n\n# Can't exec, since then the job won't be cancelled when done.\nnode=$(squeue -j $JOBID -O NodeList --noheader)\nnc $node 22\n# TODO: SLURM_JOB_ID is set in the proxied SSH job, it's hard for us\n# to control that from here.\nEOW\n</code></pre> <pre><code>cat &gt; /etc/systemd/system/user-.slice.d/10-defaults.conf &lt;&lt;EOW\nHost raapoivsc\n    ProxyCommand ssh raapoi /nfs/home/duggalro/slurm-ssh-node-proxycommand --partition quicktest --time 0-00:10:00\n    StrictHostKeyChecking no\n    UserKnownHostsFile /dev/null\n    User duggalro\n\n# You also need a cluster alias, unless you write the stuff directly\n# in ProxyCommand line ssh command above:\n\nHost *\n    ForwardAgent yes\n    ForwardX11 yes\n    ForwardX11Trusted yes\n    IdentityFile ~/.ssh/id_rsa\n    AddKeysToAgent yes\n\n\nHost raapoi\n    HostName raapoi.vuw.ac.nz\n    User duggalro\nEOW\n</code></pre> <pre><code>user@personal:~$ ssh-copy-id -i ~/.ssh/id_rsa.pub user@raapoi.vuw.ac.nz\n\n# Now should be able to get to a compute node with vs code\nConnect to host &gt; raapoivsc\n</code></pre>"},{"location":"slurm_status/","title":"Welcome to the SlurmStatus Setup","text":""},{"location":"slurm_status/#slurm-job-status","title":"Slurm Job Status","text":"<p>Slurm Status</p> slurm_status.shrun <pre><code>cat &gt; /nfs/home/$USER/slurm_status.sh &lt;&lt;EOW\n#!/usr/bin/python3\n\n# It prints for default\nimport argparse\nimport subprocess\nfrom io import StringIO\n\n\ndef memfix(inmem):\n    \"\"\"\n    Convert memory value from G to GB, or return 0 if input is 'nan' or empty.\n    \"\"\"\n    inmem = str(inmem)\n    if inmem.lower() == 'nan' or not inmem:\n        return 0\n    elif inmem.endswith('G'):\n        return float(inmem.strip('G'))\n    elif inmem.endswith('M'):\n        return round(float(inmem.strip('M')) / 1024, 2)\n    return 0\n\n\ndef parse_tres_alloc(tres_alloc):\n    \"\"\"\n    Parse the TRES allocation string to extract CPUs, memory, and GPUs.\n    \"\"\"\n    alloc_cpus = alloc_mem = alloc_gpus = 0\n    for item in tres_alloc.split(','):\n        if 'cpu' in item:\n            alloc_cpus = int(item.split('=')[1])\n        elif 'mem' in item:\n            alloc_mem = item.split('=')[1]\n        elif 'gpu' in item:\n            alloc_gpus = int(item.split('=')[1])\n    return alloc_cpus, alloc_mem, alloc_gpus\n\n\ndef group_data_by_user(data):\n    \"\"\"\n    Group job data by user and calculate aggregated values.\n    \"\"\"\n    grouped_data = {}\n    for row in data:\n        user = row['User']\n        if user not in grouped_data:\n            grouped_data[user] = {'Num Jobs': 0, 'Total CPUs': 0, 'Total GPUs': 0, 'Total Mem (GB)': 0}\n\n        grouped_data[user]['Num Jobs'] += 1\n        grouped_data[user]['Total CPUs'] += row['CPUs']\n        grouped_data[user]['Total GPUs'] += row['GPUs']\n        grouped_data[user]['Total Mem (GB)'] += row['Mem (GB)']\n\n    return grouped_data\n\n\ndef print_summary(grouped_data):\n    \"\"\"\n    Print a formatted summary of the grouped job data.\n    \"\"\"\n    print(\"{:&lt;20} {:&lt;10} {:&lt;15} {:&lt;10} {:&lt;10}\".format(\"User\", \"Num Jobs\", \"Total CPUs\", \"Total GPUs\", \"Total Mem (GB)\"))\n    print(\"-\" * 70)\n    total_jobs = total_cpus = total_gpus = total_mem = 0\n\n    for user, stats in sorted(grouped_data.items(), key=lambda x: x[1]['Total Mem (GB)'], reverse=True):\n        print(\"{:&lt;20} {:&lt;10} {:&lt;15} {:&lt;10} {:&lt;10}\".format(\n            user, stats['Num Jobs'], stats['Total CPUs'], stats['Total GPUs'], round(stats['Total Mem (GB)'], 2)\n        ))\n        total_jobs += stats['Num Jobs']\n        total_cpus += stats['Total CPUs']\n        total_gpus += stats['Total GPUs']\n        total_mem += stats['Total Mem (GB)']\n\n    print(\"-\" * 70)\n    print(\"{:&lt;20} {:&lt;10} {:&lt;15} {:&lt;10} {:&lt;10}\".format(\n        \"Total\", total_jobs, total_cpus, total_gpus, round(total_mem, 2)\n    ))\n\n\ndef usage(partition, job_state):\n    \"\"\"\n    Fetch job data from squeue, process it, and group by user.\n    \"\"\"\n    cmd = f'squeue -p {partition} -t {job_state} -O \"JobId,UserName,tres-alloc:45\" -h'\n    try:\n        squeue_output = subprocess.run(cmd, shell=True, stdout=subprocess.PIPE).stdout.decode('utf-8')\n    except Exception as e:\n        print(f\"Error executing command: {e}\")\n        return\n\n    # Parse the squeue output\n    squeue_stringio = StringIO(squeue_output)\n    data = []\n    for line in squeue_stringio:\n        if line.strip():\n            parts = line.split()\n            if len(parts) &gt;= 3:\n                job_id, user_name, tres_alloc = parts[0], parts[1], \" \".join(parts[2:])\n                alloc_cpus, alloc_mem, alloc_gpus = parse_tres_alloc(tres_alloc)\n                data.append({\n                    'User': user_name,\n                    'CPUs': alloc_cpus,\n                    'Mem (GB)': memfix(alloc_mem),\n                    'GPUs': alloc_gpus\n                })\n\n    grouped_data = group_data_by_user(data)\n    print_summary(grouped_data)\n\n\ndef main():\n    \"\"\"\n    Main function for parsing arguments and executing the script.\n    \"\"\"\n    parser = argparse.ArgumentParser(\n        description=\"Summarize SLURM job usage by user.\",\n        epilog=\"\"\"\nExamples:\nslurm_status --partition quicktest --state RUNNING\nslurm_status --partition gpu --state PENDING\nIf no arguments are provided, the script defaults to partition='general' and state='RUNNING'.\n\"\"\",\n        formatter_class=argparse.RawDescriptionHelpFormatter\n    )\n\n    parser.add_argument(\n        \"--partition\", \"-p\",\n        help=\"SLURM partition to query, e.g., 'quicktest', 'gpu', or 'longrun'. Default: 'quicktest'.\",\n        default=\"quicktest\"\n    )\n    parser.add_argument(\n        \"--state\", \"-s\",\n        help=\"SLURM job state to filter, e.g., 'RUNNING', 'PENDING', or 'COMPLETED'. Default: 'RUNNING'.\",\n        default=\"RUNNING\"\n    )\n    args = parser.parse_args()\n\n    print(f\"Fetching data for partition: {args.partition}, state: {args.state}\")\n    usage(args.partition, args.state)\n\n\nif __name__ == \"__main__\":\n    main()\n\nEOW\n</code></pre> <pre><code>user@personal:~$ bash slurm_status -h \n</code></pre>"},{"location":"status/","title":"Welcome to the SlurmStatus Setup","text":""},{"location":"status/#slurm-job-status","title":"Slurm Job Status","text":"<p>Jobs Status</p> show.shrun <pre><code>cat &gt; /nfs/home/$USER/show.sh &lt;&lt;EOW\n#!/bin/bash\n# Check if partition and job state are provided as arguments\nif [ -z \"$1\" ] || [ -z \"$2\" ]; then\necho \"Usage: $0 &lt;partition&gt; &lt;job_state&gt;\"\necho \"Example: $0 gpu,bigmem R\"\nexit 1\nfi\n\nPARTITION=$1\nJOB_STATE=$2\n\nsqueue -p $PARTITION -t $JOB_STATE -O \"JobId,UserName,tres-alloc:45\" -h | awk '{\n# Extract fields\nuser = $2\nsplit($3, tres, \",\")  # Split TRES field by commas\n# Check if the number of fields is 4 (missing \"gres/gpu\"), add \"gres/gpu=0\" if true\nif (length(tres) == 4) {\n    tres[length(tres)+1] = \"gres/gpu=0\"\n}\n# for (i in tres) print tres[i]\n    # Initialize counters\n    cpus = 0; mem = 0; gpus = 0; jobs = 0\n\n    # Loop over each element in the TRES field\n    for (i in tres) {\n        if (tres[i] ~ /cpu=/) {\n            cpus += substr(tres[i], index(tres[i], \"=\")+1)\n        }\n        else if (tres[i] ~ /mem=/) {\n            mem_val = substr(tres[i], index(tres[i], \"=\")+1)\n            # Handle different memory units (K, M, G, T)\n            if (mem_val ~ /K$/) mem += mem_val + 0\n            else if (mem_val ~ /M$/) mem += (substr(mem_val, 1, length(mem_val)-1) * 1)\n            else if (mem_val ~ /G$/) mem += (substr(mem_val, 1, length(mem_val)-1) * 1024)\n            else if (mem_val ~ /T$/) mem += (substr(mem_val, 1, length(mem_val)-1) * 1024 * 1024)\n        }\n        else if (tres[i] ~ /gpu=/) {\n            gpus += substr(tres[i], index(tres[i], \"=\")+1)\n        }\n        else if (tres[i] ~ /node=/) {\n            nodes += substr(tres[i], index(tres[i], \"=\")+1)\n        }\n    }\n\n    # Default to 1 node if node count is not explicitly specified\n    if (jobs == 0) jobs = 1\n\n    # Accumulate results per user\n    user_jobs[user] += jobs\n    total_cpus[user] += cpus\n    total_mem[user] += mem\n    total_gpus[user] += gpus\n\n    # Accumulate grand totals\n    grand_total_cpus += cpus\n    grand_total_mem += mem\n    grand_total_gpus += gpus\n    grand_total_jobs += jobs\n}\nEND {\n    # Print results per user\n    printf \"%-10s %-10s %-10s %-10s %-10s\\n\", \"User\", \"CPUs\", \"Memory(GB)\", \"GPUs\", \"Jobs\"\n    for (user in user_nodes) {\n        printf \"%-10s %-10d %-10.2f %-10d %-10d\\n\", user, total_cpus[user], total_mem[user] / 1024, total_gpus[user], user_jobs[user]\n    }\n\n    # Print grand totals\n    printf \"%-10s %-10s %-10s %-10s %-10s\\n\", \"----------\", \"----------\", \"----------\", \"----------\", \"----------\"\n    printf \"%-10s %-10d %-10.2f %-10d %-10d\\n\", \"Total\", grand_total_cpus, grand_total_mem / 1024, grand_total_gpus, grand_total_jobs\n}'\nEOW\n</code></pre> <pre><code>user@personal:~$ bash show.sh partition R\n</code></pre>"}]}